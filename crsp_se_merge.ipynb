{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#PLEASE SEE BELOW FOR TASK QUESTIONS"
      ],
      "metadata": {
        "id": "kNBJUykepJF1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Remarks\n",
        "\n",
        "Some entries in SEHeadline are generically called \"Q4 2020 earnings call\", so not directly containing any company's name; a potential solution may be to include the name from SECompanyName, even though this may lead to inconsistencies, since it only hosts the most recent ones, and such headline could refer to a moment in time when the firm was called differently.\n",
        "\n",
        "For this reason, CRSP's date column could be checked to make sure that at the call's time, the company's name was indeed the one suggested by SECompanyName, otherwise it should be fixed.\n",
        "<br><br><br>\n",
        "\n",
        "Using extractOne() initially returned the warning:\n",
        "\n",
        "\"*Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning.*\"\n",
        "\n",
        "I solved it by installing python-Levenshtein, which also decreased processing time of ~200:30 rows (se:crsp) from 6 seconds to .6 seconds (only works locally, still slow on colab).\n",
        "<br><br><br>\n",
        "\n",
        "Couldn't make pandarallel work from colab, eventually managed to get it to work locally using spyder on WSL, since I'm on Windows.\n",
        "<br><br><br>\n",
        "\n",
        "Even though the code below directly refers to se_us for extractOne(), I actually split the dataframe into several 50k row tranches, else parallel_apply() would have run for around 3 to 4 days to process the whole dataframe at once, and I couldn't afford to keep the computer turned on for such a long time.\n",
        "\n",
        "I then concatenated the 50k rows tranches and formed se_us again.\n",
        "<br><br><br>\n",
        "\n",
        "A final note on execution time, when using parallel_apply() for extractOne(), I processed 10 rows from SE with all rows from CRSP in 9 seconds, yielding a speed of approximately 1.11 rows/sec; keeping the same size for CRSP, other references I obtained using %%time were:\n",
        "\n",
        "20 rows in 15 seconds, returning 1.33 rows/sec;\n",
        "\n",
        "100 rows in ~96 seconds, returning 1.04 rows/sec;\n",
        "\n",
        "1000 rows in ~780 seconds, returning 1.28 rows/sec;\n",
        "\n",
        "10000 rows in ~9400 seconds, returning 1.06 rows/sec;\n",
        "\n",
        "40000 rows in ~31020 seconds, returning 1.29 rows/sec;\n",
        "\n",
        "50000 rows in ~38160 seconds, returning 1.31 rows/Sec\n",
        "\n",
        "Having maintained the computer approximately in the same conditions at each execution, process-wise, could it be that, depending on the rows selected, some strings are longer than others and thus require more time for processing, yielding a lower speed? Otherwise I can't explain why some executions returned approximately 1.04 rows/sec, while others 1.33 rows/sec."
      ],
      "metadata": {
        "id": "3U5U6quI3ukJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Description\n",
        "\n",
        "Initially I import the needed packages and load the data, then do some initial checks to make sure the data is prepared to be processed; I drop some SEid duplicates which were included into the main dataset, because even though they don't impact on the final result, since if the algorithm correctly matches an entry, it will also match its duplicate, it still marginally reduces the dataset's size."
      ],
      "metadata": {
        "id": "JPM9z2cNYDpB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install thefuzz"
      ],
      "metadata": {
        "id": "2Zp-xFQ0jabF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pandarallel"
      ],
      "metadata": {
        "id": "J6eBJtAAjclD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install python-Levenshtein"
      ],
      "metadata": {
        "id": "hODgo7BsjeAM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import re\n",
        "import time\n",
        "import nbconvert\n",
        "\n",
        "from thefuzz import fuzz\n",
        "from thefuzz import process\n",
        "\n",
        "from pandarallel import pandarallel\n",
        "pandarallel.initialize(nb_workers = 8, progress_bar = False)"
      ],
      "metadata": {
        "id": "qrPVta31Y8-f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "crsp = pd.read_csv(r\"CRSPnames.csv\")\n",
        "se = pd.read_csv(r\"SEmappingsDAFA.csv\")"
      ],
      "metadata": {
        "id": "c1c7qKs_ZGHA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(crsp.isnull().sum())\n",
        "\n",
        "print(se.isnull().sum())\n",
        "\n",
        "print(se[\"SEid\"].duplicated().sum())\n",
        "\n",
        "print(se[\"SEHeadline\"].duplicated().sum())"
      ],
      "metadata": {
        "id": "e0cLz4k5kEhr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Conceptually, CRSP could have duplicates in any column, but SE shouldn't have duplicates in SEId and in SEHeadline, since theoretically each row should identify a single company's specific earnings call.\n",
        "\n",
        "In practice, both SEId and SEHeadline columns contain duplicates; the former can be safely removed as they identify the same earnings call for the same company, whereas the latter shouldn't be dropped, as they identify an earnings call from the same quarter and year, but related to two different companies.\n",
        "\n",
        "Omitting these would cause information loss, and thus such action must be avoided; a potential solution has been highlighted in the Remarks section, namely appending the company's name to such \"generic\" headlines, so that they would cease being duplicates, although this would potentially cause mismatches were the company name not coherent in time.\n",
        "\n",
        "Given that there are 2213 SEId duplicates and 2891 SEHeadline duplicates, their difference could represent, as written above, the amount of lines related to earnings calls for different companies, but which have a generic name and for which appending the company's name could be useful."
      ],
      "metadata": {
        "id": "7NIZQ5C3kaUI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "se = se.drop_duplicates(subset = [\"SEid\"], keep = \"first\", ignore_index = True)"
      ],
      "metadata": {
        "id": "vmYrhwbJm5uP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "It's interesting to notice that apparently there's one more duplicate value compared to the difference 2891 - 2213 = 678, resulting from headline - id duplicates, why is this the case?\n",
        "\n",
        "Having manually investigated the dataframe with 679 duplicated entries, I have noticed rows containing information about the same earnings call, for the same company, but tied to different SEids (ex. id 840225 and 957435, both related to Q3 2004 Dr. Reddy's Laboratories Earnings Conference Call, ticker DRREDDY.NSE and company name Dr.Reddy's Laboratories Ltd).\n",
        "\n",
        "This seems to be in contrast with the statement about the id column containing unique earnings calls identifiers, but may not be relevant for merging the dataframes."
      ],
      "metadata": {
        "id": "7jTuIAoLn_PV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(se[\"SEHeadline\"].duplicated().sum())"
      ],
      "metadata": {
        "id": "iT2Mm21XoGi0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "I then split SE dataset into 2 parts: US and non US sections, according to the most frequent american business entities abbreviations, such as INC or CO, grouped with some more \"typically american\" ones such as PLC or TRUST, even though they appear less often within CRSP, as the code below shows, where the assumption is that the last word within COMNAM indeed represents the entity, which is not necessarily the case for every entry."
      ],
      "metadata": {
        "id": "UCY9TPahZlSa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "crsp[\"ENTITY\"] = crsp[\"COMNAM\"].apply(lambda x: re.findall(r\"\\w+\", x)[-1])\n",
        "\n",
        "entity_lst = crsp[\"ENTITY\"].value_counts()"
      ],
      "metadata": {
        "id": "oovTPqrP2e_P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "I also had an idea to filter out companies whose ticker isn't linked to american exchanges, but I couldn't come up with an extensive list of the potential exchanges, and I thought that anyways some american companies may also be negotiated outside american ones; another problem is that many entries do not contain an indication of the exchange where the company is negotiated (ex. 1-800 Flowers.com has some entries where its ticker is FLWS, and others where its ticker is FLWS.OQ), hence I preferred moving forward with the entity approach.\n",
        "\n",
        "Even though originally I subsequently separated se_us according to the presence of special characters (whitespace excluded) in the SEHeadline column,\n",
        "because I obtained better results in the test dataframes by using the partial ratio scorer instead of the default WRatio one, I eventually decided\n",
        "not to do it anymore and just kept a single US section, to then remove any such special character and run extractOne() with the default scorer, which yielded a better overall accuracy in the test dataframes I checked manually; those are attached to the ZIP, if you want to double check."
      ],
      "metadata": {
        "id": "9S0-q7Gl2fbY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "se_us = se[se[\"SECompanyName\"].str.contains(\"|\".join([\" INC.\", \" INC\", \" Inc.\", \" Inc\",\n",
        "                                                   \" LTD.\", \" LTD\", \" Ltd\", \" LP\",\n",
        "                                                   \" PLC\", \" Plc\", \".COM\", \".Com\"\n",
        "                                                   \" CO.\", \" CO\", \" Co.\", \" Co\",\n",
        "                                                   \" CORP\", \" CORP.\", \" Corp\", \" Corp.\",\n",
        "                                                   \" LLC\", \" Llc\", \" Lp\", \" Group\",\n",
        "                                                   \" Trust\", \" plc\"]))]\n",
        "se_us = se_us.reset_index(drop = True)\n",
        "\n",
        "se_non_us = se[~se[\"SECompanyName\"].str.contains(\"|\".join([\" INC.\", \" INC\", \" Inc.\", \" Inc\",\n",
        "                                                   \" LTD.\", \" LTD\", \" Ltd\", \" LP\",\n",
        "                                                   \" PLC\", \" Plc\", \".COM\", \".Com\"\n",
        "                                                   \" CO.\", \" CO\", \" Co.\", \" Co\",\n",
        "                                                   \" CORP\", \" CORP.\", \" Corp\", \" Corp.\",\n",
        "                                                   \" LLC\", \" Llc\", \" Lp\", \" Group\",\n",
        "                                                   \" Trust\", \" plc\"]))]\n",
        "se_non_us = se_non_us.reset_index(drop = True)\n",
        "\n",
        "se_non_us[\"MergeComnam\"] = \"NON US COMPANY\""
      ],
      "metadata": {
        "id": "LkFqIurYZ7t0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This initial filtering is based on the content of \"SECompanyName\", and not on \"SEHeadline\", because often the latter column may contain the company's name\n",
        "without its entity, leading to wrongly omitting american companies from the dataframe; this, for instance, is the case for Apple Inc, which appears as\n",
        "Apple Computer in many entries in SEHeadline prior to 2007, and not as Apple Computer Inc; in fact, having tried to filter on this column, I initially\n",
        "obtained 140k entries, versus the 275k I eventually kept when filtering on \"SECompanyName\".\n",
        "\n",
        "The datasets have their indexes reset, also further down the code, because this sensibly decreases the execution time and overall provides tidier data,\n",
        "which is easier to slice if needed."
      ],
      "metadata": {
        "id": "4xDHmxVDaG8M"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I then proceed to define one helper function to extract random datasets of length 1000, which will serve to test the algorithm and the preprocessing\n",
        "that I carry out on SEHeadline.\n",
        "\n",
        "Overall I repeated this step 5 times, and in the previous code I wrote for the task I tested 6 other dataframes of such\n",
        "size, totalling 11000 rows out of approximately 275000 from the US section, namely 4% of the US dataframe; I'm not sure this is enough to infer a result\n",
        "for the matching accuracy, but I assume it is.\n"
      ],
      "metadata": {
        "id": "0Av5-GYAafBF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def rand_df(df_start):\n",
        "    start = np.random.randint(0, len(df_start) - 1000)\n",
        "    end = start + 1000\n",
        "    df_rand = df_start.iloc[start:end].copy()\n",
        "    \n",
        "    return df_rand"
      ],
      "metadata": {
        "id": "Gdj0EKQka4RG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Another function aims at cleaning SEHeadline, with the goal of making each entry as close as possible to CRSP's counterpart,\n",
        "for example by removing the quarter and year information, and any special character which is not usually included into CRSP.\n",
        "\n",
        "Other \"distracting\" words such as \"Interim\" or \"Half Year\" are also removed at this stage, although the impact in terms of accuracy wasn't large in my test dataframes, but I decided to omit them; other potentially distracting words such as \"And\" or \"Discuss\", which appear in the original dataframe weren't removed, because the resulting list of all potentially distracting words could be very large for manual deletion.\n",
        "\n",
        "An algorithm could be conceived to recognize such words as potentially distracting, and remove them based on their frequency, or simply remove all of them, although this could lead to wrongly removing words which\n",
        "constitute the company's name.\n"
      ],
      "metadata": {
        "id": "0mxWyhwHa_MG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_df(df):\n",
        "    \n",
        "    df[\"SEHeadline_fix\"] = df[\"SEHeadline\"].str.split(\" Earnings\", 1).str[0].str.strip()\n",
        "    df[\"SEHeadline_fix\"] = df[\"SEHeadline_fix\"].str.replace(r\"\\bQ[1-4]\\b\", \" \")\n",
        "    df[\"SEHeadline_fix\"] = df[\"SEHeadline_fix\"].str.replace(r\"\\b2[0-9]{3}\\b\", \" \")\n",
        "    df[\"SEHeadline_fix\"] = df[\"SEHeadline_fix\"].str.replace(r\"[^a-zA-Z\\d\\s:]\", \" \")\n",
        "    \n",
        "    df[\"SEHeadline_fix\"] = df[\"SEHeadline_fix\"].str.replace(\"|\".join([\n",
        "                              \"Half Year\", \"Full Year\", \"Interim\", \"Preliminary\", \"Interim\",\n",
        "                              \"Conference\", \"First Quarter\", \"Second Quarter\", \"Third Quarter\",\n",
        "                              \"Fourth Quarter\", \"Results \", \"Call\", \"Fiscal\", \"FY\"]), \" \")\n",
        "    \n",
        "    df[\"SEHeadline_fix\"] = df[\"SEHeadline_fix\"].str.replace(\"Corporation\", \"Corp\")\n",
        "    df[\"SEHeadline_fix\"] = df[\"SEHeadline_fix\"].str.replace(\"Limited\", \"Ltd\")\n",
        "    \n",
        "    return df"
      ],
      "metadata": {
        "id": "-VQn_7ttb2oZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The last helper function applies the aforementioned ones to the starting dataframe, which in this case is se_us, to prepare the test dataframe for\n",
        "extractOne.\n"
      ],
      "metadata": {
        "id": "dCb0rT6AcDMV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def prep_df(df_start):\n",
        "    final_df = rand_df(df_start)\n",
        "    final_df = clean_df(final_df)\n",
        "    final_df = final_df.reset_index(drop = True)\n",
        "    \n",
        "    return final_df"
      ],
      "metadata": {
        "id": "lDhHRKOcely4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "I call the final helper function to create a test dataframe to showcase the results, and run extractOne() to get the best match according to WRatio, the default scorer.\n",
        "\n",
        "The output is then written in csv after dropping the helper column \"SEHeadline_fix\", used to merge with CRSP, with all the processing done referring to the entire CRSP dataset, meaning no slices were considered to infer results, which could otherwise be biased.\n",
        "\n",
        "The test dataframes highlight an average matching accuracy of 71% (given respectively as an average of 70% from the 6 test dataframes I manually sliced,\n",
        "plus an average of 72% stemming from the 5 random ones I selected, composed of 49%, 83%, 57%, 91% and 84%); I assumed this as an accuracy measure to\n",
        "estimate that around 70% of the companies will be correctly matched."
      ],
      "metadata": {
        "id": "ndYQFOyrfuQG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_test = prep_df(se_us)"
      ],
      "metadata": {
        "id": "11enxfg-D5hb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "df_test[\"MergeComnam\"] = df_test[\"SEHeadline_fix\"].parallel_apply(lambda x: process.extractOne(x, list(crsp[\"COMNAM\"]))[0])"
      ],
      "metadata": {
        "id": "Cn15OplTD72s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_test = df_test.drop(columns = \"SEHeadline_fix\")\n",
        "\n",
        "df_test.to_csv(\"/home/edoardo/df_test.csv\", index = False)\n"
      ],
      "metadata": {
        "id": "E_h81OvKf8hq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "I eventually apply the clean_df function to se_us, the total filtered dataframe containing data about US companies, to prepare it for extractOne(), after having estimated the matching accuracy in the previous steps, and then run the matching function.\n",
        "\n",
        "At this stage, I also drop the helper column from se_us, and check for missing values to see whether some entries were left out; at this point I realized this is not the case, even though I thought I would have some because of a warning message I received while running parallel_apply(), namely:\n",
        "\n",
        "\"*Applied processor reduces input query to empty string, all comparisons will\n",
        "have score 0.*\""
      ],
      "metadata": {
        "id": "HL9qE1_3hhyj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "se_us = clean_df(se_us)"
      ],
      "metadata": {
        "id": "pqiK3wTV1vQ0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "se_us[\"MergeComnam\"] = se_us[\"SEHeadline_fix\"].parallel_apply(lambda x: process.extractOne(x, list(crsp[\"COMNAM\"]))[0])"
      ],
      "metadata": {
        "id": "ov7tCq1S1w-G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "se_us = se_us.drop(columns = \"SEHeadline_fix\")\n",
        "\n",
        "se_us[\"MergeComnam\"].isnull().sum()"
      ],
      "metadata": {
        "id": "_fLxOQBmhwwJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "I merge back together se_us with se_non_us to get the original dataframe, filtered for duplicates, where now american companies are matched with their counterparts on CRSP, and non american companies are highlighted in the MergeComnam column as \"NON US COMPANY\"; finally, I write the output as csv."
      ],
      "metadata": {
        "id": "ltZ_meNn3tYr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "se_merge = pd.concat([se_us, se_non_us])\n",
        "\n",
        "se_merge = se_merge.reset_index(drop = True)\n",
        "\n",
        "se_merge.to_csv(\"/home/edoardo/SEmappingsDAFA_EdoardoPilla_7744044.csv\", index = False)"
      ],
      "metadata": {
        "id": "pfK8tXe-4LSU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "I load the notebook on Drive to then convert it to html using nbconvert."
      ],
      "metadata": {
        "id": "0QNhtCfd1SA0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/gdrive/\")\n",
        "\n",
        "%shell jupyter nbconvert --to html /content/gdrive/MyDrive/projects/dafa/EdoardoPilla_7744044_case1.ipynb"
      ],
      "metadata": {
        "id": "nI5p6l0R1XwW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Drawbacks\n",
        "\n",
        "Some US companies do not appear in the US dataframe, such as \"Air Canada Inc\", which is contained in CRSP.\n",
        "\n",
        "This is because the filter based on business entity is uniquely relying on the contents of SECompanyName, and not on those of SEHeadline aswell, while the company only appears as \"Air Canada\" in SECompanyName, thus being wrongly excluded from the US dataframe.\n",
        "\n",
        "Having tried to include SEHeadline as a filtering column, as shown by the code below, I ended up with a 300k entries dataframe, not shrank enough with respect to the original one, whose entries amount to 325k, to determine a sensible reduction in processing time, coupled with an increased risk of including non US companies in the US dataframe.\n",
        "\n",
        "This is the reason why, eventually, I just relied on SECompanyName to filter the dataset, even though this came at the price of neglecting occurrences such as Air Canada Inc."
      ],
      "metadata": {
        "id": "8iYe0stjl_hu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "se_us = se[(se[\"SECompanyName\"].str.contains(\"|\".join([\" INC.\", \" INC\", \" Inc.\", \" Inc\",\n",
        "                                                   \" LTD.\", \" LTD\", \" Ltd\", \" LP\",\n",
        "                                                   \" PLC\", \" Plc\", \".COM\", \".Com\"\n",
        "                                                   \" CO.\", \" CO\", \" Co.\", \" Co\",\n",
        "                                                   \" CORP\", \" CORP.\", \" Corp\", \" Corp.\",\n",
        "                                                   \" LLC\", \" Llc\", \" Lp\", \" Group\",\n",
        "                                                   \" Trust\", \" plc\"])))|\n",
        "           (se[\"SEHeadline\"].str.contains(\"|\".join([\" INC.\", \" INC\", \" Inc.\", \" Inc\",\n",
        "                                                       \" LTD.\", \" LTD\", \" Ltd\", \" LP\",\n",
        "                                                       \" PLC\", \" Plc\", \".COM\", \".Com\"\n",
        "                                                       \" CO.\", \" CO\", \" Co.\", \" Co\",\n",
        "                                                       \" CORP\", \" CORP.\", \" Corp\", \" Corp.\",\n",
        "                                                       \" LLC\", \" Llc\", \" Lp\", \" Group\",\n",
        "                                                       \" Trust\", \" plc\"])))]\n",
        "se_us = se_us.reset_index(drop = True)"
      ],
      "metadata": {
        "id": "7s67Mdokuwb0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Some non US companies still appear in the US dataframe, such as \"International consolidated airlines SA\", which is a spanish company, wrongly merged with an american one.\n",
        "\n",
        "This is because the filter based on business entity type is too rough, since non american companies can also be labelled with typically american entities, such as LTD or CORP, but I still chose to proceed in this way, because originally I tried to extract any string ending within CRSP COMNAM column, assuming it would identify the company's entity, but ended up with 1131 unique endings, which would yield a US section with around 323k rows, thus not serving enough in terms of computation reduction.\n",
        "\n",
        "This is also, intuitively, the reason why tests i carried out in the W/Y part of SE dataset are linked with lower accuracy, since many chinese companies are often labelled with CORP/CORPORATION, and start with W/Y.\n",
        "<br><br><br>\n",
        "\n",
        "Some US companies which appear in both dataframes are wrongly matched, such as for WIPRO and TARO; I believe that both instances are caused by the WRatio scorer, which weights according to the length of the substrings in order to return a match, and more specifically I think the first mismatch occurred because WIPRO is associated with \"Limited\" in SE, and is then matched with a company which has \"Limited\" in the related field in CRSP, even though it can be found within CRSP under \"WIPRO LTD\"; an ad hoc solution for this is to substitute \"Limited\" with \"Ltd\" within SE, something which I did for \"Corporation\" with \"Corp\" aswell, since it wasn't a rare occurrence, with the goal of making the entries in SE more similar to their CRSP counterparts.\n",
        "\n",
        "Even though more than 1000 entries had \"Incorporated\" in their headline, I decided not to substitute it with \"Inc\", because I wanted to balance out the\n",
        "potential mismatches caused by substituting \"Limited\" with \"Ltd\", since roughly 1000 entries had \"Limited\" in their headline.\n",
        "\n",
        "Another similar situation occurred with \"TARO PHARM CORP\" as in CRSP, available in SE as \"Taro Pharmaceuticals Industries\", wrongly matched with \"ACF INDUSTRIES\" from CRSP; following the same logic, since \"INDUSTRIES\" is more valuable than \"TARO\" for the scorer, the mismatch occurred, but I didn't fix this as, contrary to the entity case described above, a correct match would have occurred by replacing \"Industries\" with \"Corp\", but this would have just fixed few mismatches and wouldn't have been applicable to the whole dataframe.\n",
        "\n",
        "To this end, maybe something could have been done in order to filter the dataframes according to the relevant substrings' lengths, allowing WRatio to\n",
        "work more effectively, but I couldn't come up with an idea to carry this out.\n",
        "<br><br><br>\n",
        "\n",
        "Before checking manually small test dataframes, I tried to add a column labelled \"Similarity\", where I computed the different fuzz ratios available\n",
        "for the matches, but I realized that some matches which were visually correct, would have a low ratio (ex. partial ratio < 50 when using partial ratio\n",
        "as scorer), whereas others would be visually wrong, but have a high ratio (ex. WRatio > 85 when using WRatio as scorer).\n",
        "\n",
        "For this reason I checked manually to ascertain whether a match was correct or not, even though initially I tried to rely on the similarity ratios, because my idea was to label as mismatches all those entries whose related ratio (ex. WRatio when using WRatio as scorer) would be lower than a cutoff such as 70.\n",
        "<br><br><br>\n",
        "\n",
        "A potential flaw in my estimation is characterized by the fact that I set no condition to ensure that no overlapping intervals for the test dataframe\n",
        "indexes would be picked (ex. potentially code could result in same test df to be generated multiple times, or two dataframes which include,\n",
        "at some extent, the same entries such as df1 = se_us.iloc[0:1000] and df2 = se_us.iloc[600:1600]); no such occurrence happened for the test dataframes\n",
        "I selected, but I still wanted to highlight this problem.\n",
        "\n",
        "I believe the reason for this is that the original dataframe is around 275k rows, and having picked 11k, the likelihood of extracting overlapping\n",
        "intervals was low enough."
      ],
      "metadata": {
        "id": "cee7996fuw_D"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Questions\n",
        "\n",
        "**How many companies have you managed to merge?**\n",
        "\n",
        "Since extractOne left no missing values within the \"MergeComnam\" column, and given a 70% accuracy over the matching from my test dataframes, then the correctly merged headlines should amount to .7 * 275968 = 193178, where 275968 is the number of rows in se_us, the filtered dataset containing data about american companies according to my original assumption.\n",
        "\n",
        "Assuming a better filtering, maybe more american headlines could have been included into se_us, and more non american headlines could have been excluded from it, yielding a better result.\n",
        "\n",
        "Given the 48970 entries within CRSP, referring to 31803 unique PERMCOs, because each firm name must have at least one PERMCO, so the fact that the amount of entries is larger than the amount of PERMCOs means that some companies have had more than one name linked to them, then a proxy for the amount of merged companies could be .7 * 31803 = 22262, most likely overestimated due to the exclusion of some companies from se_us.\n",
        "<br><br><br>\n",
        "\n",
        "**What are the main obstacles to a perfect merge?**\n",
        "\n",
        "The algorithm, based on Levenshtein distance, potentially can't reach a perfect merge (100% accuracy), because subtle differences in strings can lead to wrong matches, especially since it's not trivial to understand which scorer should be used to determine similarity between them.\n",
        "\n",
        "In practice, these subtle differences can be determined by spelling mistakes, or by a different sorting of the tokens forming the string, even if both are semantically conveying the same message.\n",
        "\n",
        "In the task's framework, a problem is given by the many different types of headline which appear in the SE dataset, essentially not always respecting a standardized structure, allowing the algorithm to work smoothly, or at least to preprocess the entries knowing that the changes will be effective for the whole dataset.\n",
        "<br><br><br>\n",
        "\n",
        "**What is special about CRSP names? Do you preprocess CRSP names\n",
        "before merging them? If so, what changes do you make?**\n",
        "\n",
        "CRSP names are in caps lock, and in some cases they may miss characters which are actually part of a company's name, as it is the case for 1-800 Contacts.com, available as 1 800 CONTACTS INC in crsp, namely without the \"-\" and \".\" signs.\n",
        "\n",
        "However, I didn't really preprocess CRSP names, since the only query I used it for was to sort the business entities assuming that the last word was, indeed, the entity, but I aimed to make SEHeadline as similar as possible to CRSP, by removing any token which made the two strings different, for example the quarter and year information, and other special characters or potentially distracting words which may lead to mismatches; the approach I followed is explained in more detail in the Description section.\n",
        "<br><br><br>\n",
        "\n",
        "**Which tokens in the company names make your task challenging? How\n",
        "did you deal with them?**\n",
        "\n",
        "Having used the WRatio as scorer, short company names relative to the respective entity are often leading to mismatches as the scorer will value more the entity and thus match it to another company whose entity is written in the same way.\n",
        "\n",
        "All the special characters, whitespace excluded, generally decreased the matching accuracy when using WRatio, while the accuracy increased when applying the partial ratio, although eventually what led me to obtain the best accuracy was to simply remove all of them, again excluding the whitespace, and run the algorithm using the default scorer.\n",
        "\n",
        "Prior to removing quarter and year information, I also encountered some issues when dealing with companies having numbers in their names.\n",
        "<br><br><br>\n",
        "\n",
        "**What should be (theoretically) the number of records per firm’s fiscal\n",
        "year? What is the actual number of observations per firm’s fiscal year?\n",
        "Is this information helpful in identifying mismatches? Explain!**\n",
        "\n",
        "To answer this question, I use a small and readable dataset containing earnings call information about the well known high tech company APPLE INC; the code below shows that the company was first inserted into CRSP in 1980 as \"APPLE COMPUTER INC\", to then be inserted again in 2007 as \"APPLE INC\".\n",
        "\n",
        "If SE contained earnings calls information for the company since its inception in Q1 1981, up to 2020, the total amount of entries which should be visible in SE, directly related to the company, would then be (2020 - 1980) x 4 = 160, but this is not the case, since the first available data for apple's earnings call is Q2 2002, thus shrinking the total amount to (2020 - 2001) x 4 = 76 (since 2020 - 2002 would omit data for 1 year).\n",
        "\n",
        "This is almost the case, in fact when filtering for the company name, SE yields 75 entries, in fact SE misses Q1 2002 information for the company; this implies that if after merging, APPLE COMPUTER INC and APPLE INC appear, jointly, more than 75 times into SE MergeComnam, one or more mismatches occurred.\n"
      ],
      "metadata": {
        "id": "M1qPuirTqNRW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "se_apple = se[se[\"SECompanyName\"].str.contains(\"Apple Inc\")]\n",
        "\n",
        "crsp[\"DATE\"] = pd.to_datetime(crsp[\"DATE\"], format = \"%Y%m%d\")\n",
        "\n",
        "print(crsp[\"COMNAM\"][crsp[\"PERMCO\"] == 7])\n",
        "\n",
        "print(crsp[\"DATE\"][crsp[\"PERMCO\"] == 7])"
      ],
      "metadata": {
        "id": "FUzAUHjUw6px"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "More precisely, since data about Apple appears for the first time in SE in 2002, and data for one call is missing, given that the firm changed name at the beginning of 2007, 4 x 4 + 3 = 19 entries should be matched with APPLE COMPUTER INC, while 75 - 19 = 56 should be matched with APPLE INC.\n",
        "\n",
        "This makes sense since from, and including, 2007 to 2020, 14 years passed, yielding 14 x 4 = 56 calls, which are all tracked into SE.\n",
        "\n",
        "However, I haven't found a way to implement this reasoning for all the firms available, because SE isn't consistent in providing data for the same time span for each company, since some may have information starting in 2001, others starting in 2004 and so on, and some headlines may be missing from SE.\n",
        "<br><br><br>\n",
        "\n",
        "**What should be the relation between permco and the company name\n",
        "from the SEHeadline? More specifically, can one SEHeadline’s company name be correctly linked to multiple permcos (i.e., to more than\n",
        "one firm in CRSP)? Can one permco be correctly linked to multiple\n",
        "company names from SEHeadline?**\n",
        "\n",
        "Given that SEHeadline contains the company's name coherently in time (ex. APPLE COMPUTER INC before 2007, APPLE INC after 2007), while PERMCO is the unique company's identifier number, one SEheadline's name shouldn't be linkable to multiple PERMCOs, since multiple names represent the same company, but the opposite can be true (ex. APPLE COMPUTER INC. AND APPLE INC. both are linked to permco 7).\n",
        "\n",
        "To better understand this, assume that 3 companies (A, B, C) are founded at t0 and hosted in CRSP; at t0, each company has one PERMCO (1, 2, 3), and one name; at t1 (1 year and thus 4 earnings calls), company A buys company B, but nothing will change within CRSP, whereas now information about earnings call from t1 onwards will only be available for companies A and C, so at t2 SEHeadline would contain 8 entries for company A and C, and 4 for company B.\n",
        "\n",
        "If, at t2, company C changes its name to D, then a new name will be included into CRSP, and a new DATE will be uploaded too, notifying of the name change, so CRSP still hosts information about 3 companies, but C and D are now linked to PERMCO 3; at t3, 12 entries will characterize company A (which is A + B), 4 entries will characterize company B (which was bought by A and thus not updated anymore), and 12 entries will characterize company D (which was called C until t2, so 8 will be linked to C and 4 to D).\n",
        "<br><br><br>\n",
        "\n",
        "**What additional firm information would be helpful to check the validity\n",
        "of a match?**\n",
        "\n",
        "Knowing that CRSP only hosts data about US companies, knowing the firm's original nationality within SE could be helpful to determine if the names were matched correctly; in addition, as stated above, knowing when the first and last earnings call information was included into SE could aid into detecting mismatches by comparing the amount of mathes for each CRSP's company name, relative to CRSP's dates of name changes."
      ],
      "metadata": {
        "id": "9rqQbF-tw-ub"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Previous attempts\n",
        "\n",
        "Some of the codes I've previously attempted are listed here as further reference."
      ],
      "metadata": {
        "id": "_6qsEo1PpLc4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "# since the task states we should link the company name so that it's coherent at the time of the earnings call, it can be useful to convert the date column,\n",
        "# from an integer into datetime, to see how company names evolved in time\n",
        "crsp[\"DATE\"] = pd.to_datetime(crsp[\"DATE\"], format = \"%Y%m%d\")\n",
        "\n",
        "# add a column to CRSP of shape \"Qn_YYYY_COMNAM\" to increase similarity between entries from CRSP and SE (Headline column)\n",
        "q_year_comnam = []\n",
        "for i in range(len(crsp[\"DATE\"])):\n",
        "    q_year_comnam.append(\"Q{} {} {}\".format(crsp[\"DATE\"][i].quarter, crsp[\"DATE\"][i].year, crsp[\"COMNAM\"][i]))\n",
        "\n",
        "crsp[\"Q_YEAR_COMNAM\"] = q_year_comnam\n",
        "\n",
        "# add a column to SE based on SEHeadline, but without words including and after \"Earnings\", to potentially increase similarity between entries\n",
        "se[\"SEHead\"] = se['SEHeadline'].str.split('Earnings', 1).str[0].str.strip()\n",
        "\n",
        "# will try to somehow merge for apple to check whether i understood the idea, and then repeat the process for all other names\n",
        "# i already notice a possible issue since companies such as \"Applegreen PLC\" may be mistakenly involved in the fuzzy merge\n",
        "# maybe somehow possible to group companies in crsp according to their permco as filter? even if firm changed name, permco stays the same\n",
        "# also, permco can have multiple permno, but filtering directly on permco should avoid this problem?\n",
        "\n",
        "print(crsp[\"COMNAM\"][crsp[\"PERMCO\"] == 7].unique())\n",
        "print(crsp[\"DATE\"][crsp[\"PERMCO\"] == 7])\n",
        "\n",
        "# apple appears in crsp dataset twice, once as apple computer inc in 1980, and once as apple inc in 2007;\n",
        "# many other companies within crsp dataset contain \"apple\" in their names, but don't identify the famous high tech one (ex. some are called pineapple,\n",
        "# some applebaum..); a way to get all the names tied with a specific company is by specifying the permco, which uniquely identifies them,\n",
        "# regardless of their security type or other information; i could then try to pool all the possible company names by permco number,\n",
        "# and somehow use this information to merge?\n",
        "\n",
        "# create test datasets \n",
        "se_apple = se[(se[\"SEHeadline\"].str.contains(\"Apple\")) | (se[\"SEHeadline\"].str.contains(\"apple\"))]\n",
        "se_apple = se_apple.reset_index(drop = True)\n",
        "\n",
        "# having selected rows where \"apple\" appears aswell, i also include in the filtered dataset companies which have apple at some point in their names,\n",
        "# and not just at the beginning\n",
        "\n",
        "crsp_apple = crsp[crsp[\"COMNAM\"].str.contains(\"APPLE\")]\n",
        "crsp_apple = crsp_apple.reset_index(drop = True)\n",
        "\n",
        "# since the company names in crsp are always in uppercase letters, i selected \"APPLE\" instead of \"Apple\" or \"apple\";\n",
        "# i will also try to rewrite the column to contain lowercase letters, and see if this affects the performance (maybe turning uppercase to lowercase\n",
        "# is interpreted as an additional difference, so having to turn multiple letters into lowercase can affect performance sensibly?)\n",
        "\n",
        "se_apple['MergeComnam'] = se_apple[\"SEHeadline\"].apply(lambda x: process.extractOne(x, list(crsp_apple[\"COMNAM\"]))[0])\n",
        "se_apple\n",
        "\n",
        "# this \"naive\" attempt allows to see several drawbacks of the approach, in a small and readable dataset;\n",
        "# having specified nothing about a company's name changes, such as the year when this occurs, the applied name only depends on the string similarities;\n",
        "# (ex. apple computer inc applied to apple fiscal year 2008, when it had already become apple inc); having seen above that apple transitioned from\n",
        "# apple computer inc to apple inc on january 11, 2007, it's possible to see that the right thing occurs for all earnings calls in 2007, since the first\n",
        "# occurred after the name changed, and the correct (new) name according to crsp is used; another issue occurs for the call named\n",
        "# \"AppleÂ® FY 10 Second Quarter Results Conference Call\", where potentially the special characters included within trick the algorithm into thinking that\n",
        "# this line is more similar to apple computer inc.\n",
        "\n",
        "# moving on to other companies which contain \"apple\" in their names, a problem occurs for the earning call\n",
        "# \"Q3 2004 Applebee's&#174\", part of DIne Brands Global inc, whose earning calls are termed \"Applebee's international earnings call\";\n",
        "# since the characters &#174 are directly attached to \"Applebee's\", this also tricks the algorithm, and actually returns a blank entry, since it isn't\n",
        "# able to connect it to any of the choices list (crsp names), even though the other earnings calls for the same company are correctly matched.\n",
        "\n",
        "# further issues occur for the company \"Applegreen PLC\", whose earnings calls are coherently defined, but for which, probably, no counterpart in crsp is\n",
        "# included, and this leads the algorithm to recognize it as \"APPLETREE INC\", which is a different company.\n",
        "\n",
        "# another company where this happens is \"Oldapco Inc\", whose earnings call keyword is \"Appleton\"; this gets matched with apple inc, or with apple computer\n",
        "# inc when the earnings calls are termed \"Appleton Partners\" instead of just \"Appleton\"; it may be the case that this company also isn't available in crsp?\n",
        "\n",
        "# the last problem in this test dataset occurs with the company \"Keurig Dr Pepper Inc\", whose earnings calls are termed \"Dr Pepper Snapple Group Inc\";\n",
        "# these are at first correctly matched with the corresponding crsp name, but some entries have a comma (,) after the word Group, and this leads the\n",
        "# algorithm to match them with Apple Computer Inc, interesting since the comma is the only difference, but leads to moving from the correct name to the\n",
        "# wrong one\n",
        "\n",
        "crsp[crsp[\"COMNAM\"].str.contains(\"APPLEGREEN\")]\n",
        "\n",
        "# indeed, crsp dataset seems not to contain any applegreen company, potential reason why it gets matched with appletree instead\n",
        "\n",
        "crsp[crsp[\"COMNAM\"].str.contains(\"OLDAPCO\")]\n",
        "\n",
        "# same seems to happend for oldapco, as written above; not much can be done for data which simply isn't available in crsp, except maybe establishing\n",
        "# a lower bound for the matching accuracy, over which the match shouldn't occur at all? (ex. don't match for scorer_cutoff < 40)\n",
        "\n",
        "# will try to see what happens if i remove special characters such as & or #, which led to a blank entry before\n",
        "se_apple[\"SEHeadline\"] = se_apple[\"SEHeadline\"].str.replace(\"&#174\", \"\")\n",
        "se_apple['MergeComnam'] = se_apple[\"SEHeadline\"].apply(lambda x: process.extractOne(x, list(crsp_apple[\"COMNAM\"]))[0])\n",
        "se_apple\n",
        "\n",
        "# this ad hoc replacement wasn't enough to prevent the blank entry, i should probably replace it with the proper headline name,\n",
        "# but this would configure a hard coding solution, which is not suitable here since probably many such situations occur in the full dataset\n",
        "\n",
        "# removing comma from headline\n",
        "se_apple[\"SEHeadline\"] = se_apple[\"SEHeadline\"].str.replace(\",\", \"\")\n",
        "se_apple['MergeComnam'] = se_apple[\"SEHeadline\"].apply(lambda x: process.extractOne(x, list(crsp_apple[\"COMNAM\"]))[0])\n",
        "se_apple\n",
        "\n",
        "# solved the problem encountered in last company without having to change scorer in extractone\n",
        "\n",
        "# removing all non alphanumeric characters, except white space\n",
        "se_apple[\"SEHeadline\"] = se_apple[\"SEHeadline\"].str.replace(r\"[^a-zA-Z\\d\\s:]\", \"\")\n",
        "se_apple['MergeComnam'] = se_apple[\"SEHeadline\"].apply(lambda x: process.extractOne(x, list(crsp_apple[\"COMNAM\"]))[0])\n",
        "se_apple\n",
        "\n",
        "# serves same function as removing comma, but also solves the \"&#174\" problem, since apparently replacing all non alphanumeric characters except space,\n",
        "# allowed to visualize the rest of the text in that entry, thus allowing to match correctly for applebee; still didn't solve Apple fy 10 second quarter\n",
        "# line, since it only removed the special characters \"Â®\", but this wasn't enough to allow the correct match\n",
        "\n",
        "# adding on the last problem which wasn't solved, from the test dataset it's possible to see how the headline\n",
        "# \"Apple FY 06 Fourth Quarter Results Conference Call\" is matched with apple computer inc, which apparently is correct since in 2006 the company's name\n",
        "# was still that, but then the same headline, where only the year changes (ex. Apple FY 08 First Quarter Results Conference Call), still matches\n",
        "# with the old name, implying that probably the algorithm is tricked by the fact that Q4 or Q1 are written extensively;\n",
        "# a solution to this may be to drop FY and replace First Quarter with Q1, and so on for other quarters\n",
        "se_apple[\"SEHeadline\"] = se_apple[\"SEHeadline\"].str.replace(\"First Quarter\", \"Q1\")\n",
        "se_apple[\"SEHeadline\"] = se_apple[\"SEHeadline\"].str.replace(\"FY\", \"\")\n",
        "se_apple['MergeComnam'] = se_apple[\"SEHeadline\"].apply(lambda x: process.extractOne(x, list(crsp_apple[\"COMNAM\"]))[0])\n",
        "se_apple\n",
        "\n",
        "# doesn't really make a difference; i also tried to use fuzz.partial_ratio as a scorer, which basically inverted the problem, namely matching apple\n",
        "# instead of apple computer, regardless of date, but overall performance also decreased\n",
        "\n",
        "# changing crsp comnam to lowercase to see how performance is affected\n",
        "crsp_apple[\"COMNAM\"] = crsp_apple[\"COMNAM\"].str.lower()\n",
        "se_apple['MergeComnam'] = se_apple[\"SEHeadline\"].apply(lambda x: process.extractOne(x, list(crsp_apple[\"COMNAM\"]))[0])\n",
        "se_apple\n",
        "\n",
        "# performance apparently doesn't change, at least for the test dataset, as matches are exactly the same as when keeping comnam in uppercase\n",
        "\n",
        "# will try to see how things change when adding a scorer to extractone, knowing the default one is WRatio\n",
        "se_apple['MergeComnam'] = se_apple[\"SEHeadline\"].apply(lambda x: process.extractOne(x, list(crsp_apple[\"COMNAM\"]), scorer = fuzz.token_set_ratio)[0])\n",
        "se_apple\n",
        "\n",
        "# processing time decreased from 8/9 seconds to 1 second, but performance decreased sensibly, more mismatches\n",
        "\n",
        "# creating test datasets for special character case\n",
        "se_cont = se[(se[\"SEHeadline\"].str.contains(\"Contacts\")) | (se[\"SEHeadline\"].str.contains(\"CONTACTS\"))]\n",
        "se_cont = se_cont.reset_index(drop = True)\n",
        "\n",
        "crsp_cont = crsp[crsp[\"COMNAM\"].str.contains(\"CONTACTS\")]\n",
        "crsp_cont = crsp_cont.reset_index(drop = True)\n",
        "\n",
        "# makes me think that removing all special characters except for whitespace is a rough filter, should also exclude dots and - to avoid having issues with\n",
        "# such companies such as 1-800 contacts\n",
        "\n",
        "se_cont_special = se_cont[se_cont[\"SEHeadline\"].str.contains(r\"[^a-zA-Z\\d\\s:]\")]\n",
        "se_cont_special = se_cont_special.reset_index(drop = True)\n",
        "se_cont_special['MergeComnam'] = se_cont_special[\"SEHeadline\"].apply(lambda x: process.extractOne(x, list(crsp_cont[\"COMNAM\"]),\n",
        "                                 scorer = fuzz.partial_ratio)[0])\n",
        "\n",
        "# splitting df to isolate entries containing special characters allows to correctly match using partial ratio,\n",
        "# even without replacing special characters with blank spaces (at least in this case, but method may generally be too rough to be applied to whole df)\n",
        "\n",
        "se_cont_special = se_cont[se_cont[\"SEHeadline\"].str.contains(r\"[^a-zA-Z\\d\\s:]\")]\n",
        "se_cont_special = se_cont_special.reset_index(drop = True)\n",
        "se_cont_special[\"SEHeadline\"] = se_cont_special[\"SEHeadline\"].str.replace(r\"[^a-zA-Z\\d\\s:]\", \"\")\n",
        "se_cont_special['MergeComnam'] = se_cont_special[\"SEHeadline\"].apply(lambda x: process.extractOne(x, list(crsp_cont[\"COMNAM\"]),\n",
        "                                 scorer = fuzz.partial_ratio)[0])\n",
        "\n",
        "# this cell shows that the match is still correct, even after dropping the special characters; this may be helpful to fix those entries\n",
        "# having &#174 in the headline, which prevent from identifying the correct company\n",
        "\n",
        "\n",
        "se_cont[\"SEHeadline\"] = se_cont[\"SEHeadline\"].str.replace(r\"[^a-zA-Z\\d\\s:]\", \"\")\n",
        "se_cont['MergeComnam'] = se_cont[\"SEHeadline\"].apply(lambda x: process.extractOne(x, list(crsp_cont[\"COMNAM\"]), scorer = fuzz.partial_ratio)[0])\n",
        "else:\n",
        "  se_cont['MergeComnam'] = se_cont[\"SEHeadline\"].apply(lambda x: process.extractOne(x, list(crsp_cont[\"COMNAM\"]))[0])\n",
        "\n",
        "# actually, the problem here is that the crsp dataset includes 1-800 contacts as 1 800 contacts, namely without -; this leads to the wrong match,\n",
        "# regardless of the filtering applied above which removes -; actually, if the special characters were to be replaced by an empty space,\n",
        "# would this change something?\n",
        "\n",
        "# UPDATE: replacing with an empty space didn't change anything, but using the partial_ratio as a scorer fixed this problem;\n",
        "# this can be an hint for situations where companies have numbers in their names?\n",
        "\n",
        "# split SE into two parts: one whose headline column contains special characters (excluding whitespace), one not containing them\n",
        "se_special = se[se[\"SEHeadline\"].str.contains(r\"[^a-zA-Z\\d\\s:]\")]\n",
        "se_no_special = se[~se[\"SEHeadline\"].str.contains(r\"[^a-zA-Z\\d\\s:]\")]\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "3KZemV24rqFb"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}